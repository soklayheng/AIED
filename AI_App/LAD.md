---
# Learning Analytic Dashboard (LAD)
  
| Objective | Dataset | AI model | Methods | Limitation | Ref |  
| ---------------- | ------------ | -------------- | ------------------------- | ------------------------------------------------------------------ | ------------ | 
| Propose a GenAI-based pipeline that automatically turns collaborative learning data into narrative feedback inside LDA. Student-facing | Recorded online meetings (MS Teams) from an OOP collaborative activity | Whisper for ASR, GPT-3.5 | GPT-3.5 to automatically code collaboration behaviours from class meeting transcripts (generated by whisper), automatically generate narrative summaries and feedback (data stories) for students and groups. Compute the agreement between human coding and GenAI results using Cohenâ€™s Kappa, Integrate these narratives output (JSON) into a GenAI-powered dashboard prototype. Get insights from a pilot test. | Accuracy will be based on transcibed scipts. Transcripts had to be split into 900-word chunks to fit GPT-3.5 constraints, which may cause loss of global context and affect coding accuracy. Data Privacy|[2024](https://github.com/soklayheng/AIED/blob/main/references/593895957_oa.pdf)| 
| Propose self-service, teacher-facing learning analytics dashboard where teachers can build and refine dashboard charts by using natural-language requests | Collected classroom data from a VR story-creation learning platform (LAVR) used in a university course, including student info, VR story artifacts, peer reviews, and behavior logs/clickstreams | GPT-4o vs GPT-4o mini | Store the student's collected data in PostgreSQL database. Prompt-engineering  to retrieve data from SQL, Vega specification for Chart rendering. Usability testing with teachers.|limited participants for usability study, prompt-engineering-by-teachers |[2025](https://github.com/soklayheng/AIED/blob/main/references lak2025-23.pdf) | 
| Propose 2 dashboards: Conventional (reactive) chatbot: answers only when the learner asks.Scaffolding (proactive) chatbot: guiding users through visualisations with
structured narratives and scaffolding questions crafted by human experts + feedback. as there is a challenge with prompt engineering literacy. Student-facing| Multimodal sensor data from a healthcare simulation to generate the dashboard visualisations (Positioning data + audio data + heart rate) | GPT-4o | RAG (to avoid hallucination) implemented with LangChain + Chroma, embeddings using OpenAI text-embedding-ada-002, responses generated with GPT-4o multimodal capabilities. VizChat for Chatbot prototype| no study if the proposed model really helps SRL, no personalized scaffolding (should be adaptive LA) | [2025](https://github.com/soklayheng/AIED/blob/main/references/2411.15597v1.pdf) | 
